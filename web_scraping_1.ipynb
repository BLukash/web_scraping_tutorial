{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web scraping 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObN7xeqYTDZKluniQJ0w9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BLukash/web_scraping_tutorial/blob/main/web_scraping_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEgeA12OP4C8"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) 2021 Bohdan Lukashchuk\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeWnaJaPDHtH"
      },
      "source": [
        "# First lets install needed libraries (note, running locally on your PC you may need to install more of them)\n",
        "# Для початку встановимо необхідні бібліотеки (зауваження, для запуску на ПК може знадобитися інсталювати більше бібліотек)\n",
        "%%capture\n",
        "! pip3 install newspaper3k"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ8YQBaUDDKI"
      },
      "source": [
        "**Newspaper3k: Article scraping & curation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ClDh74ADFhu"
      },
      "source": [
        "import pandas as pd\n",
        "import newspaper"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFl8kZwfnPeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767b00d6-d3a7-44d7-cad9-c2414e2d490d"
      },
      "source": [
        "# Lets retrieve and print all URL-addresses of srticles, present on 'https://www.pravda.com.ua/news/'\n",
        "# Отримаємо і виведемо всі URL-адреси статей, наявних на сторінці 'https://www.pravda.com.ua/news/'\n",
        "news_page_url = \"https://www.pravda.com.ua/news/\"\n",
        "news_page = newspaper.build(news_page_url)\n",
        "article_urls = [article.url for article in news_page.articles]\n",
        "print(article_urls)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.pravda.com.ua/news/2021/10/26/7311733/', 'https://www.pravda.com.ua/news/2021/10/26/7311732/', 'https://www.pravda.com.ua/news/2021/10/26/7311731/', 'https://www.epravda.com.ua/news/2021/10/26/679077/', 'https://www.pravda.com.ua/news/2021/10/26/7311729/', 'https://www.epravda.com.ua/news/2021/10/26/679073/', 'https://www.pravda.com.ua/news/2021/10/26/7311727/', 'https://www.pravda.com.ua/news/2021/10/26/7311726/', 'https://www.pravda.com.ua/news/2021/10/26/7311725/', 'https://www.pravda.com.ua/news/2021/10/26/7311722/', 'https://www.pravda.com.ua/news/2021/10/26/7311721/', 'https://www.epravda.com.ua/news/2021/10/26/679069/', 'https://life.pravda.com.ua/society/2021/10/26/246295/', 'https://www.epravda.com.ua/news/2021/10/26/679067/', 'https://www.pravda.com.ua/news/2021/10/26/7311717/', 'https://www.epravda.com.ua/news/2021/10/26/679066/', 'https://www.pravda.com.ua/news/2021/10/26/7311713/', 'https://www.pravda.com.ua/news/2021/10/26/7311712/', 'https://www.epravda.com.ua/news/2021/10/26/679065/', 'https://www.pravda.com.ua/news/2021/10/26/7311710/', 'https://www.pravda.com.ua/news/2021/10/26/7311709/', 'https://www.pravda.com.ua/news/2021/10/26/7311707/', 'https://www.pravda.com.ua/news/2021/10/26/7311708/', 'https://www.pravda.com.ua/news/2021/10/26/7311706/', 'https://www.pravda.com.ua/news/2021/10/26/7311705/', 'https://www.epravda.com.ua/news/2021/10/26/679063/', 'https://www.pravda.com.ua/news/2021/10/26/7311701/', 'https://www.epravda.com.ua/news/2021/10/26/679057/', 'https://www.pravda.com.ua/news/2021/10/26/7311700/', 'https://www.pravda.com.ua/news/2021/10/26/7311699/', 'https://www.eurointegration.com.ua/articles/2021/10/26/7129447/', 'http://life.pravda.com.ua/culture/2021/10/26/246297/', 'http://life.pravda.com.ua/society/2021/10/26/246295/', 'http://life.pravda.com.ua/society/2021/10/26/246294/', 'https://www.pravda.com.ua/columns/2021/10/26/7311724/', 'https://www.pravda.com.ua/columns/2021/10/26/7311586/', 'https://www.epravda.com.ua/news/2021/10/26/678999/', 'https://www.pravda.com.ua/news/2021/10/25/7311617/', 'https://www.epravda.com.ua/publications/2021/10/26/679076/', 'https://www.eurointegration.com.ua/news/2021/10/26/7129477/', 'https://www.eurointegration.com.ua/news/2021/10/26/7129476/', 'https://www.eurointegration.com.ua/news/2021/10/26/7129470/', 'https://www.eurointegration.com.ua/news/2021/10/26/7129475/', 'http://www.pravda.com.ua/news/2021/10/26/7311717/', 'http://www.pravda.com.ua/news/2021/10/26/7311710/', 'http://www.pravda.com.ua/news/2021/10/26/7311709/', 'http://www.pravda.com.ua/news/2021/10/26/7311708/', 'http://www.pravda.com.ua/news/2021/10/26/7311733/', 'http://www.pravda.com.ua/news/2021/10/26/7311732/', 'http://www.pravda.com.ua/news/2021/10/26/7311731/', 'http://www.pravda.com.ua/news/2021/10/26/7311729/', 'http://www.pravda.com.ua/news/2021/10/26/7311727/', 'http://www.pravda.com.ua/news/2021/10/26/7311726/', 'http://www.pravda.com.ua/news/2021/10/26/7311725/', 'http://www.pravda.com.ua/news/2021/10/26/7311722/', 'http://www.pravda.com.ua/news/2021/10/26/7311721/', 'http://www.pravda.com.ua/news/2021/10/26/7311713/', 'http://www.pravda.com.ua/news/2021/10/26/7311712/', 'http://www.pravda.com.ua/news/2021/10/26/7311707/', 'http://www.pravda.com.ua/news/2021/10/26/7311706/', 'http://www.pravda.com.ua/news/2021/10/26/7311705/', 'http://www.pravda.com.ua/news/2021/10/26/7311701/', 'http://www.pravda.com.ua/news/2021/10/26/7311700/', 'http://www.pravda.com.ua/news/2021/10/26/7311699/', 'http://www.pravda.com.ua/columns/2021/10/26/7311724/', 'http://www.pravda.com.ua/columns/2021/10/26/7311586/', 'http://www.pravda.com.ua/news/2021/10/25/7311617/', 'https://life.pravda.com.ua/culture/2021/10/26/246297/', 'https://life.pravda.com.ua/society/2021/10/26/246294/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToXNVlZaQIkF",
        "outputId": "3590173f-3c86-428f-80d1-bba79780965a"
      },
      "source": [
        "# Filter out and print that addresses, that correspond to the seeking news, we will use regular expressions module for that\n",
        "# Відфільтруємо і виведемо ті адреси, які відносяться саме до новин, використаємо модуль регулярних виразів\n",
        "import re\n",
        "\n",
        "news_urls = list(filter(lambda url: re.match('https://www.pravda.com.ua/news/\\d', url), article_urls))\n",
        "print(news_urls)\n",
        "print(len(news_urls))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.pravda.com.ua/news/2021/10/26/7311733/', 'https://www.pravda.com.ua/news/2021/10/26/7311732/', 'https://www.pravda.com.ua/news/2021/10/26/7311731/', 'https://www.pravda.com.ua/news/2021/10/26/7311729/', 'https://www.pravda.com.ua/news/2021/10/26/7311727/', 'https://www.pravda.com.ua/news/2021/10/26/7311726/', 'https://www.pravda.com.ua/news/2021/10/26/7311725/', 'https://www.pravda.com.ua/news/2021/10/26/7311722/', 'https://www.pravda.com.ua/news/2021/10/26/7311721/', 'https://www.pravda.com.ua/news/2021/10/26/7311717/', 'https://www.pravda.com.ua/news/2021/10/26/7311713/', 'https://www.pravda.com.ua/news/2021/10/26/7311712/', 'https://www.pravda.com.ua/news/2021/10/26/7311710/', 'https://www.pravda.com.ua/news/2021/10/26/7311709/', 'https://www.pravda.com.ua/news/2021/10/26/7311707/', 'https://www.pravda.com.ua/news/2021/10/26/7311708/', 'https://www.pravda.com.ua/news/2021/10/26/7311706/', 'https://www.pravda.com.ua/news/2021/10/26/7311705/', 'https://www.pravda.com.ua/news/2021/10/26/7311701/', 'https://www.pravda.com.ua/news/2021/10/26/7311700/', 'https://www.pravda.com.ua/news/2021/10/26/7311699/', 'https://www.pravda.com.ua/news/2021/10/25/7311617/']\n",
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAIdHBTsU5re"
      },
      "source": [
        "# We can also just hardcode the list of URL's\n",
        "# Ми можемо задати вручну список URL-адрес\n",
        "# news_urls = ['https://www.pravda.com.ua/news/2021/10/14/7310463/', 'https://www.pravda.com.ua/news/2021/10/14/7310462/', 'https://www.pravda.com.ua/news/2021/10/14/7310461/', 'https://www.pravda.com.ua/news/2021/10/14/7310460/', 'https://www.pravda.com.ua/news/2021/10/14/7310458/', 'https://www.pravda.com.ua/news/2021/10/14/7310455/', 'https://www.pravda.com.ua/news/2021/10/14/7310453/', 'https://www.pravda.com.ua/news/2021/10/14/7310451/', 'https://www.pravda.com.ua/news/2021/10/14/7310450/', 'https://www.pravda.com.ua/news/2021/10/14/7310448/', 'https://www.pravda.com.ua/news/2021/10/14/7310446/', 'https://www.pravda.com.ua/news/2021/10/14/7310447/', 'https://www.pravda.com.ua/news/2021/10/14/7310445/', 'https://www.pravda.com.ua/news/2021/10/14/7310444/', 'https://www.pravda.com.ua/news/2021/10/14/7310443/', 'https://www.pravda.com.ua/news/2021/10/14/7310442/', 'https://www.pravda.com.ua/news/2021/10/14/7310441/', 'https://www.pravda.com.ua/news/2021/10/14/7310440/', 'https://www.pravda.com.ua/news/2021/10/14/7310439/', 'https://www.pravda.com.ua/news/2021/10/14/7310438/', 'https://www.pravda.com.ua/news/2021/10/14/7310437/', 'https://www.pravda.com.ua/news/2021/10/13/7310415/', 'https://www.pravda.com.ua/news/2021/10/13/7310410/', 'https://www.pravda.com.ua/news/2021/10/13/7310407/', 'https://www.pravda.com.ua/news/2021/10/13/7310403/', 'https://www.pravda.com.ua/news/2021/10/13/7310390/', 'https://www.pravda.com.ua/news/2021/10/13/7310429/', 'https://www.pravda.com.ua/news/2021/10/13/7310412/', 'https://www.pravda.com.ua/news/2021/10/13/7310411/', 'https://www.pravda.com.ua/news/2021/10/13/7310405/', 'https://www.pravda.com.ua/news/2021/10/13/7310354/', 'https://www.pravda.com.ua/news/2021/10/13/7310376/', 'https://www.pravda.com.ua/news/2021/10/13/7310388/', 'https://www.pravda.com.ua/news/2021/10/13/7310387/', 'https://www.pravda.com.ua/news/2021/10/13/7310386/', 'https://www.pravda.com.ua/news/2021/10/13/7310391/']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rp9-Pz9OQV7"
      },
      "source": [
        "Надалі детальні коментарі до класів/функцій/методів будуть представлені у вигляді Python docstrings англійською, українською будуть короткі описи звичайними коментарями перед функцією/класом/методом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWxITOFbv_-V"
      },
      "source": [
        "\n",
        "# Функція для отримання інформації зі статті, за переданою URL-адресою\n",
        "# Надалі всі функції, класи матимуть розширену документацію у вигляді docstring англійською\n",
        "def get_article_info(url):\n",
        "    # Docstrings is a perfect way to create code documentation, you can check by calling help(get_article_info) to check effect\n",
        "    # You can get some usefull info and rules on docstrings here - 'https://www.python.org/dev/peps/pep-0257/'\n",
        "    # Docstrings - чудовий спосіб для створенн документації, можете перевірити викликавши help(get_article_info)\n",
        "    # Корисна інформація і правила щодо doctrings знаходяться за посиланням - 'https://www.python.org/dev/peps/pep-0257/'\n",
        "    \"\"\"\n",
        "    Load page, using passed url (arg1) and extract information from it.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): URL of article to extract data from.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Dictionary with keys 'authors'=None, 'date'=None, 'top_image'=None, 'text'=None, with data from article.  \n",
        "    \"\"\"\n",
        "    article = newspaper.Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return {\n",
        "        'authors': article.authors or None,\n",
        "        'date': article.publish_date or None,\n",
        "        'top_image': article.top_image or None,\n",
        "        'text': article.text or None,\n",
        "    }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgOE9yYySLTR"
      },
      "source": [
        "# Отримати Pandas DataFrame, наповнений даними зі статей, що знаходяться за переданими URL-адресами\n",
        "def fill_df_with_article_info(urls):\n",
        "    \"\"\"\n",
        "    Creates a Pandas DataFrame, filled with info from the passed urls.\n",
        "\n",
        "    Parameters:\n",
        "        ursl (list): List of URL's to get daat from.\n",
        "\n",
        "    Returns:\n",
        "        (DataFrame): Pandas DataFrame filled article data from the passed URL's.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame()\n",
        "    for url in urls:\n",
        "        data = data.append(get_article_info(url), ignore_index=True)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miLR56X91_7w"
      },
      "source": [
        "# Отримаймо Pandas DataFrame, наповнений даними зі сторінок\n",
        "# Retrieve Pandas DataFrame with data from the pages\n",
        "pravda_news_data = fill_df_with_article_info(news_urls)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "zQSFq6MO2Elq",
        "outputId": "9f6bcab5-3836-41c6-e346-7167169f3585"
      },
      "source": [
        "# Методом 'samle' виведемо 10 випадкових рядків, кожен рядок відповідає 1 статті\n",
        "# Using 'sample' method, print 10 rows, each row corrsponds to 1 article\n",
        "pravda_news_data.sample(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>top_image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[Фото Ріа Новости]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>В окупованому Росією Криму за минулу добу зафі...</td>\n",
              "      <td>https://img.pravda.com/images/doc/d/4/d46a3e1-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[Фото Опу]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>Президент Володимир Зеленський заявив, що Укра...</td>\n",
              "      <td>https://img.pravda.com/images/doc/0/f/0f1506b-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[Фото Getty Images]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>В Україні запустили в тестовому режимі роботу ...</td>\n",
              "      <td>https://img.pravda.com/images/doc/d/a/da19244-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Фото Getty Images]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>У Китаї запроваджують локдаун у 4-мільйонному ...</td>\n",
              "      <td>https://img.pravda.com/images/doc/f/f/ffb9b39-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[Дмитро Разумков. Фото З Сайту Вр]</td>\n",
              "      <td>2021-10-25</td>\n",
              "      <td>Апарат Верховної Ради переадресував питання що...</td>\n",
              "      <td>https://img.pravda.com/images/doc/e/1/e10350c-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Фото Ельдара Сарахмана, Скриншот З Трансляції]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>Експерти Київської школи економіки прогнозують...</td>\n",
              "      <td>https://img.pravda.com/images/doc/4/7/4729e13-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>ПАТ \"Квіти України\" просить Окружний адмінсуд ...</td>\n",
              "      <td>https://img.pravda.com/images/doc/7/3/7311727_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[Фото Ріа Новости]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>Окупаційна влада окремих районів Донецької обл...</td>\n",
              "      <td>https://img.pravda.com/images/doc/8/d/8db272b-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[Володимир Зеленський, Фото Getty Images]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>Із серпня охочих проголосувати на виборах за п...</td>\n",
              "      <td>https://img.pravda.com/images/doc/1/b/1b344f9-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[Фото]</td>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>У Харківській області оштрафували мережу магаз...</td>\n",
              "      <td>https://img.pravda.com/images/doc/d/d/dd56691-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            authors  ...                                          top_image\n",
              "19                               [Фото Ріа Новости]  ...  https://img.pravda.com/images/doc/d/4/d46a3e1-...\n",
              "11                                       [Фото Опу]  ...  https://img.pravda.com/images/doc/0/f/0f1506b-...\n",
              "9                               [Фото Getty Images]  ...  https://img.pravda.com/images/doc/d/a/da19244-...\n",
              "3                               [Фото Getty Images]  ...  https://img.pravda.com/images/doc/f/f/ffb9b39-...\n",
              "21               [Дмитро Разумков. Фото З Сайту Вр]  ...  https://img.pravda.com/images/doc/e/1/e10350c-...\n",
              "5   [Фото Ельдара Сарахмана, Скриншот З Трансляції]  ...  https://img.pravda.com/images/doc/4/7/4729e13-...\n",
              "4                                              None  ...  https://img.pravda.com/images/doc/7/3/7311727_...\n",
              "16                               [Фото Ріа Новости]  ...  https://img.pravda.com/images/doc/8/d/8db272b-...\n",
              "15        [Володимир Зеленський, Фото Getty Images]  ...  https://img.pravda.com/images/doc/1/b/1b344f9-...\n",
              "7                                            [Фото]  ...  https://img.pravda.com/images/doc/d/d/dd56691-...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhHKNZF12UL2"
      },
      "source": [
        "**Beautiful Soup + requests** **library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg9ArmEr2ctp"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQmYOY2iM-iF"
      },
      "source": [
        "Розгялнемо парсинг сайтів з довільною структурою. Ми будемо завантажувати HTML-сторінку сайту за його URL-адресою, використовуючи бібліотеку **requests**, після чого за допомогою **BeautifulSoup** парситимемо його і зберігатимо дані у **pandas DataFrame**\n",
        "\n",
        "Let's consider parsing of web sites with arbitrary structure.\n",
        "First we will load HTML-page, using web site URL address, using **requests** library, then parse it with **BeautifulSoup** and store data in **pandas DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOuI3OihOo-U"
      },
      "source": [
        "Познайомимося з класами в Python, та простим варіантом патерну Фабрика. Використавши їх, ми матимемо скелет для створення скрапера для сайту з будь-якою структурою. (Хтось може вважати це оверінжинірингом, але я впевнений, що для навчальної мети цей приклад підходить)\n",
        "\n",
        "Let's get acquainted with classes in Python, as well as simple implementation of Factory pattern. With them, we will have a base structure to create scraper for web site wuth any structure. (Someone may consider this to be overengineering, but I am sure, that for educational purposes this example suits great)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYesGHfwL1Jn"
      },
      "source": [
        "Корисні посилання (useful links):\n",
        "\n",
        "https://docs.python.org/3/tutorial/classes.html\n",
        "\n",
        "https://www.tutorialspoint.com/design_pattern/factory_pattern.htm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgEOTVAvO9Yi"
      },
      "source": [
        "Для представлення моделі також можна було б використати декоратор @dataclass.\n",
        "Але я вирішив не ускладнювати приклади.\n",
        "\n",
        "We can also use @dataclass operator to create 'model'.\n",
        "But I decided not to make exampels more complex.\n",
        "\n",
        "https://www.python.org/dev/peps/pep-0318/\n",
        "\n",
        "https://docs.python.org/3/library/dataclasses.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuH2SNU5tYSB"
      },
      "source": [
        "# Представлення моделі для сторінки з піснею\n",
        "class PisniModel:\n",
        "    \"\"\"\n",
        "    Class representing model for one song page from 'https://www.pisni.org.ua/'.\n",
        "\n",
        "    Attributes:\n",
        "        title (str): song title.\n",
        "        author (str): song author.\n",
        "        text (str): song text.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, title=None, author=None, text=None):\n",
        "        \"\"\"\n",
        "        The constructor of PisniModel class. Parameters are the same as class attributes.\n",
        "\n",
        "        Parameters:\n",
        "            title=None (str): song title.\n",
        "            author=None (str): song author.\n",
        "            text=None (str): song text.\n",
        "        \"\"\"\n",
        "        self.title = title\n",
        "        self.author = author\n",
        "        self.text = text\n",
        "\n",
        "    # Конвертація даних моделі у словник\n",
        "    def to_dict(self):\n",
        "        \"\"\"\n",
        "        Get class instance data in form of dictionary.\n",
        "\n",
        "        Returns:\n",
        "            (dict): dictionary with keys: 'title', 'author', 'text', that represent one song.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'title': self.title,\n",
        "            'author': self.author,\n",
        "            'text': self.text\n",
        "        }\n",
        "\n",
        "# Базовий клас-скрапер\n",
        "class BaseScraper:\n",
        "    \"\"\"\n",
        "    Base class, that should be inherited, while creating some scraper.\n",
        "    Contains basic functionality for collecting data from multiple URL-s,\n",
        "    filling Pandas DataFrame with the collected data\n",
        "    (or just fill ordinary list with model instances).\n",
        "    Contains 'parse_page' method without implementation, should be implemented in\n",
        "    the inherited classes.\n",
        "\n",
        "    Attributes:\n",
        "        model (type): class, representing model for one page, scraped from one URL.\n",
        "        urls=[] (list): list of URL's of pages to scrape, if we want to define them during insatnce creation.\n",
        "        pandas_format=True (bool): define if pandas DataFrame or list of model instances should be used to store data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, urls=[], pandas_format=True):\n",
        "        self.model = model\n",
        "        self.pandas_format = pandas_format\n",
        "        self.urls = urls\n",
        "\n",
        "    # Отримання контейнера для даних (Pandas DataFrame або список, в залежності від початкових налаштувань)\n",
        "    def get_data_container(self):\n",
        "        \"\"\"\n",
        "        Get empty data container. Pandas DataFrame or list, depending on the instance setup.\n",
        "\n",
        "        Returns:\n",
        "            (DataFrame or list): container to store data from pages.\n",
        "        \"\"\"\n",
        "        return pd.DataFrame() if self.pandas_format else []\n",
        "\n",
        "    # Додавання до контейнера, даних з нової зіскрапленої сторінки\n",
        "    def add_data_to_data_container(self, data_instance, data_container):\n",
        "        \"\"\"\n",
        "        Add data model instance of one scraped page to data container.\n",
        "\n",
        "        Parameters:\n",
        "            data_instance (model type instance): instance of model class, container for one page data.\n",
        "            data_container (DataFrame of list): container data from multiple pages.\n",
        "\n",
        "        Returns:\n",
        "            (DataFrame or list): data_container with new page data added\n",
        "        \"\"\"\n",
        "        if self.pandas_format:\n",
        "            return data_container.append(data_instance.to_dict(), ignore_index=True)\n",
        "        \n",
        "        return [*data_container, data_instance]\n",
        "\n",
        "\n",
        "    # Метод для парсингу сторінки, повинен бути імплементований вже в конкретному скрапері\n",
        "    def parse_page(self, soup):\n",
        "        \"\"\"\n",
        "        Should be implemented in child classes and include logic of one page scraping.\n",
        "\n",
        "        Parameters:\n",
        "            soup (BeautifulSoup): used to extract data from page DOM structure.\n",
        "        \n",
        "        Returs:\n",
        "            (dict): dictionary, where keys represent extracted fields.\n",
        "        \"\"\"\n",
        "        pass \n",
        "\n",
        "    # Створює інстанс моделі із переданих даних\n",
        "    def get_data_instance(self, parsed_info):\n",
        "        \"\"\"\n",
        "        Convert dictionary with page data to model instance.\n",
        "\n",
        "        Parameters:\n",
        "            parsed_info (dict): dictionary, where keys represent extracted fields.\n",
        "        \"\"\"\n",
        "        return self.model(**parsed_info)\n",
        "\n",
        "    # Відвідує і скрапить сторінки, що знаходяться за переданими URL-адресами\n",
        "    def scrape(self, urls=None):\n",
        "        \"\"\"\n",
        "        Load each url, call 'parse' method on it and collect data into data_container.\n",
        "\n",
        "        Parameters:\n",
        "            urls=None (list): list of URL's to scrape, if None is passed - URL's from constructor are used.\n",
        "\n",
        "        Returns:\n",
        "            (DataFrame or list): data_container - Pandas DataFrame or list with info from scraped pages.\n",
        "        \"\"\"\n",
        "        # important - this is a shallow copy!\n",
        "        urls_to_scrape = self.urls.copy()\n",
        "        if urls is not None:\n",
        "            urls_to_scrape = urls\n",
        "\n",
        "        data_container = self.get_data_container()\n",
        "        for page_url in urls_to_scrape:\n",
        "            page = requests.get(page_url)\n",
        "            page_html = page.text\n",
        "            soup = BeautifulSoup (page_html, 'html.parser')\n",
        "            parsed_info = self.parse_page(soup)\n",
        "            data_container = self.add_data_to_data_container(\n",
        "                self.get_data_instance(parsed_info),\n",
        "                data_container\n",
        "            )\n",
        "\n",
        "        return data_container\n",
        "\n",
        "# Конкретна імплементація скрапера для пісень на сайті 'https://www.pisni.org.ua/'\n",
        "class PisniScraper(BaseScraper):\n",
        "    \"\"\"\n",
        "    Is inherited from BaseScraper. Implements specific scraper implementation to scrape\n",
        "    song pages from 'https://www.pisni.org.ua/'.\n",
        "\n",
        "    Attributes: inherited from parent class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, urls=[], pandas_format=True):\n",
        "        \"\"\"\n",
        "        Constructor of PisniScraper. Parameters are inherited from BaseScraper.\n",
        "        Inherits parent constructor behaviour.\n",
        "        \"\"\"\n",
        "        super().__init__(model, urls, pandas_format)\n",
        "\n",
        "    # Конкретна імплементація парсингу сторінки\n",
        "    def parse_page(self, soup):\n",
        "        \"\"\"\n",
        "        Overrides (implements) parent 'parse_page' method. Implements parsing of\n",
        "        'pisni.org.ua' song pages. For example: 'https://www.pisni.org.ua/songs/21277.html'.\n",
        "\n",
        "        Parameters: inherited from the base class.\n",
        "\n",
        "        Returns:\n",
        "            (dict): dictionary of song data with keys - 'title'=None, 'author'=None, 'text'=None.\n",
        "        \"\"\"\n",
        "        title = soup.find('h1', {'class': 'nomarg'})\n",
        "        text = soup.find('pre', {'class': 'songwords'})\n",
        "\n",
        "        author_element = soup.select('td i a.dyn')\n",
        "        author = author_element and author_element[0] and author_element[0].text or None\n",
        "\n",
        "        return {\n",
        "            'title': title and title.text or None,\n",
        "            'author': author,\n",
        "            'text': text and text.text or None\n",
        "        }\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxPckoQVR9hC"
      },
      "source": [
        "# Фабрика скраперів\n",
        "class ScraperFactory:\n",
        "    \"\"\"\n",
        "    Class that implement simple Factory pattern for scrapers creation\n",
        "\n",
        "    Attributes:\n",
        "        scrapers_map=None (dict): Dictionary that represent possible scrapers.\n",
        "        Example: {\n",
        "                'Pisni': {\n",
        "                    'type': PisniScraper,\n",
        "                    'model': PisniModel\n",
        "                }\n",
        "            }\n",
        "         Where top level key ('Pisni' here) - key of scraper to create,\n",
        "         'type' - scraper class, 'model' - page model for data from one page, scraped with instance of 'type' scraper.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, scrapers_map=None):\n",
        "        \"\"\"\n",
        "        Constructor for ScraperFactory class. If 'scrapers_map' is not passed - default value is used.\n",
        "        Check class description 'Attributes' -> 'Example' for the default value\n",
        "\n",
        "        Parameters:\n",
        "            scrapers_map=None (dict): Check class description for more info on this.\n",
        "        \"\"\"\n",
        "        if scrapers_map:\n",
        "            self.scrapers_map = scrapers_map\n",
        "        else:\n",
        "            self.scrapers_map = {\n",
        "                'Pisni': {\n",
        "                    'type': PisniScraper,\n",
        "                    'model': PisniModel\n",
        "                }\n",
        "            }\n",
        "\n",
        "    # Метод для створення скрапера, по переданому типу\n",
        "    def create_scraper(self, scraper_type, urls=[], pandas_format=True):\n",
        "        \"\"\"\n",
        "        Create instance of specific scraper, according to passed type.\n",
        "\n",
        "        Parameters:\n",
        "            scraper_type (str): type of scraper, to be created, should be present in 'self.scrapers_map'.\n",
        "            urls=[] (list): scraper parameter - list of URL's of pages to scrape, if we want to define them during insatnce creation.\n",
        "            pandas_format=True (bool): scraper parameter - define if pandas DataFrame or list of model instances should be used to store data.\n",
        "\n",
        "        Returns:\n",
        "            (instance of scraper type) - scraper, ready for scraping).\n",
        "        \"\"\"\n",
        "        scraper_config = self.scrapers_map[scraper_type]\n",
        "        if not scraper_config:\n",
        "            raise Exception('No scraper config for the passed scraper type')\n",
        "\n",
        "        scraper_type = scraper_config['type']\n",
        "        scraper_model = scraper_config['model']\n",
        "        return scraper_type(scraper_model, urls, pandas_format)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGSNQaCdUtYb"
      },
      "source": [
        "# Створимо екземпляр ScraperFactory, щоб створювати конкретні скрапери в подальшому\n",
        "# Create instance of ScraperFactory, to create specific scrapers further\n",
        "scraper_factory = ScraperFactory()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1LgcTykXy7Z"
      },
      "source": [
        "# Отримання екземпляру скрапера для пісень з сайту 'https://www.pisni.org.ua'\n",
        "# Retrieving scraper instance for songs from web site 'https://www.pisni.org.ua'\n",
        "pisni_scraper = scraper_factory.create_scraper('Pisni')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7NenWpxw-Ll"
      },
      "source": [
        "# Скрапінг сторінок, що знаходяться за переданими URL-адресами\n",
        "# Scraping of pages, according to passed list of URL's\n",
        "scraped_page = pisni_scraper.scrape(['https://www.pisni.org.ua/songs/21277.html', 'https://www.pisni.org.ua/songs/216199.html', 'https://www.pisni.org.ua/songs/443032.html', 'https://www.pisni.org.ua/songs/817205.html'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "1kT_5PbzxjlP",
        "outputId": "12692489-47a7-4d11-92f3-60ed00eae34b"
      },
      "source": [
        "# Вивід перших рядків зіскраплених даних\n",
        "# Pring few first rows of scraped data\n",
        "scraped_page.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Мертвий півень</td>\n",
              "      <td>G                             C\\nСтарий си...</td>\n",
              "      <td>Для тебе *</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "      <td>Am            E Am\\nНова радість стала,\\nC   ...</td>\n",
              "      <td>Нова радість стала **</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Андрій Хливнюк</td>\n",
              "      <td>Вступ:\\n\\n|-------------|-------------|-------...</td>\n",
              "      <td>Квiти в волоссi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Вадим Красноокий</td>\n",
              "      <td>Intro: C G Am F\\n\\nAm               G\\nКоли оп...</td>\n",
              "      <td>Надія є</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             author  ...                  title\n",
              "0    Мертвий півень  ...             Для тебе *\n",
              "1              None  ...  Нова радість стала **\n",
              "2    Андрій Хливнюк  ...        Квiти в волоссi\n",
              "3  Вадим Красноокий  ...                Надія є\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}